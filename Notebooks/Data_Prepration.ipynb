{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6031adeb-349c-48d0-846e-f89647782c12",
   "metadata": {},
   "source": [
    "# Data Prepration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27897f33-8fa5-4ad3-9abe-d0e8a9253425",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data will be saved in: C:\\Users\\haier\\AI_Stock_Analyzer\\Data\\raw\n",
      "\n",
      "Fetching data for AAPL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview of AAPL data:\n",
      "                 Open       High        Low      Close     Volume\n",
      "Date                                                             \n",
      "2017-01-03  28.950001  29.082500  28.690001  29.037500  115127600\n",
      "2017-01-04  28.962500  29.127501  28.937500  29.004999   84472400\n",
      "2017-01-05  28.980000  29.215000  28.952499  29.152500   88774400\n",
      "2017-01-06  29.195000  29.540001  29.117500  29.477501  127007600\n",
      "2017-01-09  29.487499  29.857500  29.485001  29.747499  134247600\n",
      "Saved 2012 rows for AAPL\n",
      "\n",
      "\n",
      "Fetching data for TSLA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview of TSLA data:\n",
      "                 Open       High        Low      Close     Volume\n",
      "Date                                                             \n",
      "2017-01-03  14.324000  14.688667  14.064000  14.466000   88849500\n",
      "2017-01-04  14.316667  15.200000  14.287333  15.132667  168202500\n",
      "2017-01-05  15.094667  15.165333  14.796667  15.116667   88675500\n",
      "2017-01-06  15.128667  15.354000  15.030000  15.267333   82918500\n",
      "2017-01-09  15.264667  15.461333  15.200000  15.418667   59692500\n",
      "Saved 2012 rows for TSLA\n",
      "\n",
      "\n",
      "Fetching data for MSFT...\n",
      "Preview of MSFT data:\n",
      "                 Open       High        Low      Close    Volume\n",
      "Date                                                            \n",
      "2017-01-03  62.790001  62.840000  62.130001  62.580002  20694100\n",
      "2017-01-04  62.480000  62.750000  62.119999  62.299999  21340000\n",
      "2017-01-05  62.189999  62.660000  62.029999  62.299999  24876000\n",
      "2017-01-06  62.299999  63.150002  62.040001  62.840000  19922900\n",
      "2017-01-09  62.759998  63.080002  62.540001  62.639999  20382700\n",
      "Saved 2012 rows for MSFT\n",
      "\n",
      "\n",
      "Fetching data for AMZN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview of AMZN data:\n",
      "                 Open       High        Low      Close     Volume\n",
      "Date                                                             \n",
      "2017-01-03  37.896000  37.938000  37.384998  37.683498   70422000\n",
      "2017-01-04  37.919498  37.984001  37.709999  37.859001   50210000\n",
      "2017-01-05  38.077499  39.119999  38.013000  39.022499  116602000\n",
      "2017-01-06  39.118000  39.972000  38.924000  39.799500  119724000\n",
      "2017-01-09  39.900002  40.088501  39.588501  39.846001   68922000\n",
      "Saved 2012 rows for AMZN\n",
      "\n",
      "\n",
      "Fetching data for NVDA...\n",
      "Preview of NVDA data:\n",
      "               Open     High      Low    Close      Volume\n",
      "Date                                                      \n",
      "2017-01-03  2.61000  2.65925  2.48450  2.55025  1501996000\n",
      "2017-01-04  2.58500  2.63750  2.53825  2.60975  1199220000\n",
      "2017-01-05  2.61325  2.64550  2.52625  2.54350   984296000\n",
      "2017-01-06  2.57125  2.60625  2.53000  2.57750   822856000\n",
      "2017-01-09  2.58750  2.70000  2.58750  2.68200   916248000\n",
      "Saved 2012 rows for NVDA\n",
      "\n",
      "Data collection complete.\n",
      "Cleaned CSV files saved to: C:\\Users\\haier\\AI_Stock_Analyzer\\Data\\raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Path to raw data folder (relative to your project root)\n",
    "raw_data_folder = r\"C:\\Users\\haier\\AI_Stock_Analyzer\\Data\\raw\"\n",
    "os.makedirs(raw_data_folder, exist_ok=True)\n",
    "\n",
    "print(f\"Data will be saved in: {raw_data_folder}\")\n",
    "\n",
    "# List of tickers\n",
    "tickers = [\"AAPL\", \"TSLA\", \"MSFT\", \"AMZN\", \"NVDA\"]\n",
    "\n",
    "# Fetch 8 years of data\n",
    "start_date = \"2017-01-01\"\n",
    "end_date = \"2025-01-01\"\n",
    "\n",
    "all_data = {}\n",
    "\n",
    "for ticker in tickers:\n",
    "    print(f\"\\nFetching data for {ticker}...\")\n",
    "    try:\n",
    "        # Download data\n",
    "        df = yf.download(ticker, start=start_date, end=end_date, auto_adjust=False)\n",
    "\n",
    "        if df.empty:\n",
    "            print(f\"Warning: No data found for {ticker}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Flatten MultiIndex columns if any\n",
    "        if isinstance(df.columns, pd.MultiIndex):\n",
    "            df.columns = [col[0] for col in df.columns]\n",
    "\n",
    "        # Drop Adj Close if present\n",
    "        if \"Adj Close\" in df.columns:\n",
    "            df.drop(columns=[\"Adj Close\"], inplace=True)\n",
    "\n",
    "        # Keep only OHLCV\n",
    "        df = df[['Open', 'High', 'Low', 'Close', 'Volume']]\n",
    "\n",
    "        # Ensure Date is index\n",
    "        df.index.name = \"Date\"\n",
    "\n",
    "        # Save to CSV\n",
    "        save_path = os.path.join(raw_data_folder, f\"{ticker}.csv\")\n",
    "        df.to_csv(save_path)\n",
    "\n",
    "        # Store in dictionary for preview\n",
    "        all_data[ticker] = df\n",
    "\n",
    "        # Show preview\n",
    "        print(f\"Preview of {ticker} data:\")\n",
    "        print(df.head())\n",
    "        print(f\"Saved {len(df)} rows for {ticker}\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching {ticker}: {e}\")\n",
    "\n",
    "print(\"Data collection complete.\")\n",
    "print(\"Cleaned CSV files saved to:\", raw_data_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbc94fe-6e09-4cbc-ba45-a452af9f3226",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda7] *",
   "language": "python",
   "name": "conda-env-anaconda7-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
